{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91023e1f63324974beb3269b837bb98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05abf06d1a284c0d995add5f0c7cddf1",
              "IPY_MODEL_e39b2ab3c4524997abfd2c9293c17bfa",
              "IPY_MODEL_4b039c71ffb44e77bc3cbd8b1453656f"
            ],
            "layout": "IPY_MODEL_98a7836ca656477db92e241579f5db88"
          }
        },
        "05abf06d1a284c0d995add5f0c7cddf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f609fb4c482549489d3f2b62140bffa8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ca0209ee9a52424eb96ab068de3e65f7",
            "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
          }
        },
        "e39b2ab3c4524997abfd2c9293c17bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24522bcf73b6456388e384a857b5d7c4",
            "max": 19704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b86f6201f7cd4a77ad547054547c4775",
            "value": 19704
          }
        },
        "4b039c71ffb44e77bc3cbd8b1453656f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f63477454664db4836278e6ec8c9927",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56a2266b9f89467cbbceb5f48c3727df",
            "value": "â€‡19704/19704â€‡[00:01&lt;00:00,â€‡16481.82â€‡examples/s]"
          }
        },
        "98a7836ca656477db92e241579f5db88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f609fb4c482549489d3f2b62140bffa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0209ee9a52424eb96ab068de3e65f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24522bcf73b6456388e384a857b5d7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86f6201f7cd4a77ad547054547c4775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f63477454664db4836278e6ec8c9927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a2266b9f89467cbbceb5f48c3727df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e895dd5abfef4f118f53a8abf67c6b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5aadf7e679a44074b5725671899758ec",
              "IPY_MODEL_2b7fd0622c4d4e8a93fbc6137b12660a",
              "IPY_MODEL_241f641211a742a09eda2336d3c51016"
            ],
            "layout": "IPY_MODEL_557af351c832490e81c74d7bc7bd0185"
          }
        },
        "5aadf7e679a44074b5725671899758ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9c0b43b3bae4f08b0c48defe904e257",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_09133621471c4a8998f8d461a7715d1a",
            "value": "Map:â€‡100%"
          }
        },
        "2b7fd0622c4d4e8a93fbc6137b12660a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96da29a543a442ba2667380ccbae844",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5754b81a3e54e30a2ab7bda0a37b8d4",
            "value": 500
          }
        },
        "241f641211a742a09eda2336d3c51016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0709f7f9765542c2ab818d6e741f5a88",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7c201b73e113410293ad64b009a2c8c6",
            "value": "â€‡500/500â€‡[00:00&lt;00:00,â€‡6798.56â€‡examples/s]"
          }
        },
        "557af351c832490e81c74d7bc7bd0185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9c0b43b3bae4f08b0c48defe904e257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09133621471c4a8998f8d461a7715d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a96da29a543a442ba2667380ccbae844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5754b81a3e54e30a2ab7bda0a37b8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0709f7f9765542c2ab818d6e741f5a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c201b73e113410293ad64b009a2c8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da93e06055ef461bbace9c4a3c5c92b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d64a5aad141b4c06848cd2671221f7bc",
              "IPY_MODEL_0f21740e80674d4b85e63891222e0d8f",
              "IPY_MODEL_2fe6bc69b01248db9e6f1260c146a909"
            ],
            "layout": "IPY_MODEL_4f778f1c5f1d40eb900539cb643da7b2"
          }
        },
        "d64a5aad141b4c06848cd2671221f7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_461df1cb05994643b09d0e104e77e9ee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e4cac12eaf9d4e1abc5fbe43d66f5d3e",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]:â€‡â€‡â€‡0%"
          }
        },
        "0f21740e80674d4b85e63891222e0d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f555b5c572404324ba199e9cc68f1d54",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6a5dc1688ad41328ba04add990a2d8e",
            "value": 0
          }
        },
        "2fe6bc69b01248db9e6f1260c146a909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852be7270cfd4edf81e0abc6b8dbc5e3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ca511743844b49d5a9d07059d0c18c14",
            "value": "â€‡0/500â€‡[00:01&lt;?,â€‡?â€‡examples/s]"
          }
        },
        "4f778f1c5f1d40eb900539cb643da7b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "461df1cb05994643b09d0e104e77e9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4cac12eaf9d4e1abc5fbe43d66f5d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f555b5c572404324ba199e9cc68f1d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a5dc1688ad41328ba04add990a2d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "852be7270cfd4edf81e0abc6b8dbc5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca511743844b49d5a9d07059d0c18c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOG4HjRPTChB",
        "outputId": "6beab274-d33a-40c0-e487-37fdda0aecc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI with Hassan\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.5.10)\n",
            "Collecting git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-8mdq6udj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-8mdq6udj\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 8c432a9d52a735f66fe1d3bcdfc0b2b0dc271a2e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.5.10-py3-none-any.whl size=277060 sha256=865711736e8b08eea249d1eea9d65f04e5aec47dbe6c8e8c92d8956cdbb88341\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zuw8afyv/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "  Attempting uninstall: unsloth\n",
            "    Found existing installation: unsloth 2025.5.10\n",
            "    Uninstalling unsloth-2025.5.10:\n",
            "      Successfully uninstalled unsloth-2025.5.10\n",
            "Successfully installed unsloth-2025.5.10\n",
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"AI-Doctor-3.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1uX6cjANPaW1kTRzXSoBAvKHx7EsNsUQH\n",
        "\"\"\"\n",
        "\n",
        "print(\"AI with Hassan\")\n",
        "\n",
        "# Step1: Create & Setup hugging face API token in Collab\n",
        "\n",
        "!pip install unsloth # install unsloth\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!\n",
        "\n",
        "# Step3: Import necessary libraries\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from unsloth import is_bfloat16_supported\n",
        "from huggingface_hub import login\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step4: Check HF token\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get('helping_19')\n",
        "login(hf_token)"
      ],
      "metadata": {
        "id": "OClSkDvdWiwG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Check GPU availability\n",
        "# Test if CUDA is available\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYYFvl95WnkD",
        "outputId": "33a76d47-534b-45c4-b589-794fe1b7bdb7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Check GPU availability\n",
        "# Test if CUDA is available\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# Step5: Setup pretrained DeepSeek-R1\n",
        "\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "max_sequence_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmyQp4fAWxJl",
        "outputId": "97d07a15-56e9-47d1-9c76-97870eb9041d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgx2KqUGW4al",
        "outputId": "08c685a1-f85e-4f01-ef30-22f11fd0ea93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.5.10: Fast Llama patching. Transformers: 4.52.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step6: Setup system prompt\n",
        "prompt_style = \"\"\"\n",
        "Below is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\n",
        "\n",
        "Before crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\n",
        "\n",
        "### Task:\n",
        "You are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "<think>{}\n",
        "\"\"\"\n",
        "\n",
        "# Step7: Run Inference on the model\n",
        "\n",
        "# Define a test question\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\n",
        "              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "\n",
        "print(response)\n",
        "\n",
        "print(response[0].split(\"### Answer:\")[1])\n",
        "\n",
        "# Step8: Setup fine-tuning\n",
        "\n",
        "# Load Dataset\n",
        "medical_dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split = \"train[:500]\", trust_remote_code = True)\n",
        "\n",
        "medical_dataset[1]\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which tells the model when to stop generating text during training\n",
        "EOS_TOKEN\n",
        "\n",
        "### Finetuning\n",
        "# Updated training prompt style to add </think> tag\n",
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "Please answer the following medical question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\"\n",
        "\n",
        "# Prepare the data for fine-tuning\n",
        "\n",
        "def preprocess_input_data(examples):\n",
        "  inputs = examples[\"Question\"]\n",
        "  cots = examples[\"Complex_CoT\"]\n",
        "  outputs = examples[\"Response\"]\n",
        "\n",
        "  texts = []\n",
        "\n",
        "  for input, cot, output in zip(inputs, cots, outputs):\n",
        "    text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "    texts.append(text)\n",
        "\n",
        "  return {\n",
        "      \"texts\" : texts,\n",
        "  }\n",
        "\n",
        "finetune_dataset = medical_dataset.map(preprocess_input_data, batched = True)\n",
        "\n",
        "finetune_dataset[\"texts\"][0]\n",
        "\n",
        "\n",
        "\n",
        "# Step9: Setup/Apply LoRA finetuning to the model\n",
        "\n",
        "model_lora = FastLanguageModel.get_peft_model(\n",
        "    model = model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3047,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")\n",
        "\n",
        "# Add this before creating the trainer\n",
        "if hasattr(model, '_unwrapped_old_generate'):\n",
        "    del model._unwrapped_old_generate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEParrY2YJrj",
        "outputId": "6e887564-c54f-4d75-d5c0-99fa1fa8be5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"<ï½œbeginâ–ofâ–sentenceï½œ>\\nBelow is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\\n\\nBefore crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\\n\\n### Task:\\nYou are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\\n\\n### Query:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\\n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\\n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Answer:\\n<think>\\nOkay, so I have this medical case to analyze. Let me try to break it down step by step. \\n\\nThe patient is a 61-year-old woman with a history of involuntary urine loss when she coughs or sneezes, but she doesn't leak at night. She's undergoing a gynecological exam and a Q-tip test. The question is asking what cystometry would most likely reveal about her residual volume and detrusor contractions.\\n\\nFirst, I need to understand the key points here. She's experiencing urinary incontinence, specifically when she coughs or sneezes. That makes me think of stress urinary incontinence (SUI) because those are activities that can put pressure on the bladder and cause leakage. However, she doesn't leak at night, which is more common in other types of incontinence like urge incontinence (UI) where people might leak when they can't get to the bathroom quickly enough.\\n\\nNow, the gynecological exam and Q-tip test. The Q-tip test is usually used to assess urethral function. The Q-tip is a small catheter that measures the closure pressure of the urethral sphincter. If the pressure is low, it suggests that the sphincter isn't functioning well, which could be related to SUI because the sphincter isn't effectively closing to prevent leakage.\\n\\nCystometry, also known as a bladder diary or filling test, is used to measure how much the bladder can hold and how it responds to filling. It's often used to diagnose whether someone has an overactive bladder or if their bladder capacity is too small, leading to UI.\\n\\nSo, putting this together, the findings from the Q-tip test might show that the urethral sphincter has low resistance, which is typical in SUI. Then, during cystometry, if she has SUI, her bladder would likely have a normal capacity, but she might have an unstable sphincter that doesn't close properly when there's pressure, like from coughing.\\n\\nWait, but she doesn't leak at night. That makes me think that her bladder capacity is normal because if it were small, she might leak even when lying down. So the residual volume after voiding would be within normal limits, and the detrusor muscle (the main muscle of the bladder) would function normally, meaning it contracts well when it should. However, the sphincter isn't contracting properly to prevent leakage during activities that cause pressure.\\n\\nSo, the cystometry would probably show normal residual volume and normal detrusor contractions, but the sphincter function would be impaired, leading to the observed SUI symptoms.\\n</think>\\n\\n**Answer:**\\n\\nThe cystometry findings in this 61-year-old woman with a history of stress urinary incontinence (SUI) upon coughing or sneezing, but no nighttime leakage, would most likely reveal the following:\\n\\n1. **Residual Volume**: The residual volume of her bladder would be within the normal range. This is because she does not experience leakage at night, which suggests that her bladder capacity is adequate and not overly small.\\n\\n2. **Detrusor Contractions**: The detrusor muscle would function normally, meaning it would contract appropriately during the filling phase of the bladder, indicating that the main muscle responsible for bladder emptying is functioning correctly.\\n\\n3. **Sphincter Function**: The urethral sphincter would demonstrate impaired closure during the Q-tip test, consistent with the presence of SUI. This would explain the involuntary leakage during activities that increase intra-abdominal pressure, such as coughing or sneezing.\\n\\nIn summary, cystometry would show normal residual volume and detrusor contractions, but impaired sphincter function, confirming the diagnosis of stress urinary incontinence.<ï½œendâ–ofâ–sentenceï½œ>\"]\n",
            "\n",
            "<think>\n",
            "Okay, so I have this medical case to analyze. Let me try to break it down step by step. \n",
            "\n",
            "The patient is a 61-year-old woman with a history of involuntary urine loss when she coughs or sneezes, but she doesn't leak at night. She's undergoing a gynecological exam and a Q-tip test. The question is asking what cystometry would most likely reveal about her residual volume and detrusor contractions.\n",
            "\n",
            "First, I need to understand the key points here. She's experiencing urinary incontinence, specifically when she coughs or sneezes. That makes me think of stress urinary incontinence (SUI) because those are activities that can put pressure on the bladder and cause leakage. However, she doesn't leak at night, which is more common in other types of incontinence like urge incontinence (UI) where people might leak when they can't get to the bathroom quickly enough.\n",
            "\n",
            "Now, the gynecological exam and Q-tip test. The Q-tip test is usually used to assess urethral function. The Q-tip is a small catheter that measures the closure pressure of the urethral sphincter. If the pressure is low, it suggests that the sphincter isn't functioning well, which could be related to SUI because the sphincter isn't effectively closing to prevent leakage.\n",
            "\n",
            "Cystometry, also known as a bladder diary or filling test, is used to measure how much the bladder can hold and how it responds to filling. It's often used to diagnose whether someone has an overactive bladder or if their bladder capacity is too small, leading to UI.\n",
            "\n",
            "So, putting this together, the findings from the Q-tip test might show that the urethral sphincter has low resistance, which is typical in SUI. Then, during cystometry, if she has SUI, her bladder would likely have a normal capacity, but she might have an unstable sphincter that doesn't close properly when there's pressure, like from coughing.\n",
            "\n",
            "Wait, but she doesn't leak at night. That makes me think that her bladder capacity is normal because if it were small, she might leak even when lying down. So the residual volume after voiding would be within normal limits, and the detrusor muscle (the main muscle of the bladder) would function normally, meaning it contracts well when it should. However, the sphincter isn't contracting properly to prevent leakage during activities that cause pressure.\n",
            "\n",
            "So, the cystometry would probably show normal residual volume and normal detrusor contractions, but the sphincter function would be impaired, leading to the observed SUI symptoms.\n",
            "</think>\n",
            "\n",
            "**Answer:**\n",
            "\n",
            "The cystometry findings in this 61-year-old woman with a history of stress urinary incontinence (SUI) upon coughing or sneezing, but no nighttime leakage, would most likely reveal the following:\n",
            "\n",
            "1. **Residual Volume**: The residual volume of her bladder would be within the normal range. This is because she does not experience leakage at night, which suggests that her bladder capacity is adequate and not overly small.\n",
            "\n",
            "2. **Detrusor Contractions**: The detrusor muscle would function normally, meaning it would contract appropriately during the filling phase of the bladder, indicating that the main muscle responsible for bladder emptying is functioning correctly.\n",
            "\n",
            "3. **Sphincter Function**: The urethral sphincter would demonstrate impaired closure during the Q-tip test, consistent with the presence of SUI. This would explain the involuntary leakage during activities that increase intra-abdominal pressure, such as coughing or sneezing.\n",
            "\n",
            "In summary, cystometry would show normal residual volume and detrusor contractions, but impaired sphincter function, confirming the diagnosis of stress urinary incontinence.<ï½œendâ–ofâ–sentenceï½œ>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.10 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(finetune_dataset.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gebIKvTnVmF",
        "outputId": "e792f3de-00fe-4c3d-fcda-8a45fd1d4759"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Question', 'Complex_CoT', 'Response', 'texts']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_func(example):\n",
        "    question = example.get(\"Question\", \"\")\n",
        "    cot = example.get(\"Complex_CoT\", \"\")\n",
        "    response = example.get(\"Response\", \"\")\n",
        "    texts=example.get(\"texts\", \"\")\n",
        "\n",
        "    try:\n",
        "        prompt = train_prompt_style.format(question, cot, response,texts) + EOS_TOKEN\n",
        "    except Exception as e:\n",
        "        print(\"Prompt formatting failed:\", e)\n",
        "        prompt = f\"Q: {question}\\nCOT: {cot}\\nA: {response} \\nT:{texts}{EOS_TOKEN}\"\n",
        "\n",
        "    return [prompt]\n"
      ],
      "metadata": {
        "id": "o6r9D841l_hV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Zng33vkoIia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model_lora,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = finetune_dataset,\n",
        "    formatting_func=formatting_func,\n",
        "\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dataset_num_proc = 1,\n",
        "\n",
        "    # Define training args\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_train_epochs = 1,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314,
          "referenced_widgets": [
            "da93e06055ef461bbace9c4a3c5c92b0",
            "d64a5aad141b4c06848cd2671221f7bc",
            "0f21740e80674d4b85e63891222e0d8f",
            "2fe6bc69b01248db9e6f1260c146a909",
            "4f778f1c5f1d40eb900539cb643da7b2",
            "461df1cb05994643b09d0e104e77e9ee",
            "e4cac12eaf9d4e1abc5fbe43d66f5d3e",
            "f555b5c572404324ba199e9cc68f1d54",
            "b6a5dc1688ad41328ba04add990a2d8e",
            "852be7270cfd4edf81e0abc6b8dbc5e3",
            "ca511743844b49d5a9d07059d0c18c14"
          ]
        },
        "id": "RYFIQMU4djAa",
        "outputId": "53653249-0744-424c-a2f3-55609c39ac95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da93e06055ef461bbace9c4a3c5c92b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ArrowInvalid",
          "evalue": "Column 4 named input_ids expected length 500 but got length 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0e4faef8e642>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lora\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mformatting_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/trainer.py\u001b[0m in \u001b[0;36mnew_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0moriginal_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0mfix_zero_training_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 )\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             train_dataset = self._prepare_dataset(\n\u001b[0m\u001b[1;32m    536\u001b[0m                 \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpacking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatting_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             )\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m_prepare_dataset\u001b[0;34m(self, dataset, processing_class, args, packing, formatting_func, dataset_name)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_desc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"desc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Unsloth: Tokenizing [\"{dataset_text_field}\"]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmap_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# If VLM, switch data collator since .pad is needed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m         }\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3077\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3079\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3080\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[1;32m   3538\u001b[0m                                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3540\u001b[0;31m                                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_original_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_original_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3541\u001b[0m                         \u001b[0mnum_examples_progress_update\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_examples_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPBAR_REFRESH_TIME_INTERVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36mwrite_batch\u001b[0;34m(self, batch_examples, writer_batch_size, try_original_type)\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0minferred_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyped_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inferred_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferred_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrow_schema\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpa_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mpa_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.from_arrays\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.validate\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: Column 4 named input_ids expected length 500 but got length 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_func(example):\n",
        "    question = example[\"Question\"]\n",
        "    cot = example[\"Complex_CoT\"]\n",
        "    response = example[\"Response\"]\n",
        "\n",
        "    prompt = train_prompt_style.format(question, cot, response) + EOS_TOKEN\n",
        "    return [prompt]  # âœ… VERY important: return a list of strings\n",
        "\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model_lora,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = medical_dataset,  # use raw dataset if using formatting_func\n",
        "    formatting_func = formatting_func,  # âœ… this is the actual function now\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dataset_num_proc = 1,\n",
        "\n",
        "    # Training args\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_train_epochs = 1,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "E-23SZHEaM0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step6: Setup system prompt\n",
        "prompt_style = \"\"\"\n",
        "Below is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\n",
        "\n",
        "Before crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\n",
        "\n",
        "### Task:\n",
        "You are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "<think>{}\n",
        "\"\"\"\n",
        "\n",
        "# Step7: Run Inference on the model\n",
        "\n",
        "# Define a test question\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\n",
        "              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "\n",
        "print(response)\n",
        "\n",
        "print(response[0].split(\"### Answer:\")[1])\n",
        "\n",
        "# Step8: Setup fine-tuning\n",
        "\n",
        "# Load Dataset\n",
        "medical_dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split = \"train[:500]\", trust_remote_code = True)\n",
        "\n",
        "medical_dataset[1]\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which tells the model when to stop generating text during training\n",
        "EOS_TOKEN\n",
        "\n",
        "### Finetuning\n",
        "# Updated training prompt style to add </think> tag\n",
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "Please answer the following medical question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\"\n",
        "\n",
        "# Prepare the data for fine-tuning\n",
        "\n",
        "def preprocess_input_data(examples):\n",
        "  inputs = examples[\"Question\"]\n",
        "  cots = examples[\"Complex_CoT\"]\n",
        "  outputs = examples[\"Response\"]\n",
        "\n",
        "  texts = []\n",
        "\n",
        "  for input, cot, output in zip(inputs, cots, outputs):\n",
        "    text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "    texts.append(text)\n",
        "\n",
        "  return {\n",
        "      \"texts\" : texts,\n",
        "  }\n",
        "\n",
        "finetune_dataset = medical_dataset.map(preprocess_input_data, batched = True)\n",
        "\n",
        "finetune_dataset[\"texts\"][0]\n",
        "\n",
        "\n",
        "\n",
        "# Step9: Setup/Apply LoRA finetuning to the model\n",
        "\n",
        "model_lora = FastLanguageModel.get_peft_model(\n",
        "    model = model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3047,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")\n",
        "\n",
        "# Add this before creating the trainer\n",
        "if hasattr(model, '_unwrapped_old_generate'):\n",
        "    del model._unwrapped_old_generate\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model_lora,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = finetune_dataset,\n",
        "    dataset_text_field = \"texts\",\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dataset_num_proc = 1,\n",
        "\n",
        "    # Define training args\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_train_epochs = 1,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Setup WANDB\n",
        "from google.colab import userdata\n",
        "wnb_token = userdata.get(\"WANDB_API_TOKEN\")\n",
        "# Login to WnB\n",
        "wandb.login(key=wnb_token) # import wandb\n",
        "run = wandb.init(\n",
        "    project='Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")\n",
        "\n",
        "# Start the fine-tuning process\n",
        "trainer_stats = trainer.train()\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "# Step10: Testing after fine-tuning\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing\n",
        "              but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response)\n",
        "\n",
        "print(response[0].split(\"### Answer:\")[1])\n",
        "\n",
        "question = \"\"\"A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue,\n",
        "              and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative,\n",
        "              gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium.\n",
        "              What is the most likely predisposing factor for this patient's condition?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response[0].split(\"### Answer:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "91023e1f63324974beb3269b837bb98c",
            "05abf06d1a284c0d995add5f0c7cddf1",
            "e39b2ab3c4524997abfd2c9293c17bfa",
            "4b039c71ffb44e77bc3cbd8b1453656f",
            "98a7836ca656477db92e241579f5db88",
            "f609fb4c482549489d3f2b62140bffa8",
            "ca0209ee9a52424eb96ab068de3e65f7",
            "24522bcf73b6456388e384a857b5d7c4",
            "b86f6201f7cd4a77ad547054547c4775",
            "2f63477454664db4836278e6ec8c9927",
            "56a2266b9f89467cbbceb5f48c3727df",
            "e895dd5abfef4f118f53a8abf67c6b66",
            "5aadf7e679a44074b5725671899758ec",
            "2b7fd0622c4d4e8a93fbc6137b12660a",
            "241f641211a742a09eda2336d3c51016",
            "557af351c832490e81c74d7bc7bd0185",
            "e9c0b43b3bae4f08b0c48defe904e257",
            "09133621471c4a8998f8d461a7715d1a",
            "a96da29a543a442ba2667380ccbae844",
            "a5754b81a3e54e30a2ab7bda0a37b8d4",
            "0709f7f9765542c2ab818d6e741f5a88",
            "7c201b73e113410293ad64b009a2c8c6"
          ]
        },
        "id": "4R7-AInSTl9_",
        "outputId": "5bb5c154-67c5-45c5-9261-0909492b8f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"<ï½œbeginâ–ofâ–sentenceï½œ>\\nBelow is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\\n\\nBefore crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\\n\\n### Task:\\nYou are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\\n\\n### Query:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\\n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\\n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Answer:\\n<think>\\nOkay, so I'm trying to figure out what cystometry would show for this 61-year-old woman. Let me start by breaking down the information given.\\n\\nShe has a history of involuntary urine loss when she coughs or sneezes, but she doesn't leak at night. That makes me think of stress urinary incontinence. I remember that stress incontinence is usually due to weak pelvic muscles or urethral issues, and it happens when there's increased abdominal pressure, like from coughing.\\n\\nShe underwent a gynecological exam and a Q-tip test. I'm not entirely sure what the Q-tip test entails, but I think it's a way to check for urethral obstruction. If the Q-tip is up high, it might mean the urethra is partially blocked. But I'm not certain, so I should double-check that.\\n\\nNow, considering cystometry, which I know is a test to measure how the bladder behaves. It can show things like how much the bladder can hold (residual volume) and how it contracts (detrusor contractions). If she has stress incontinence, I expect the residual volume to be normal because she doesn't leak at night, which suggests she doesn't have volume issues. But during the Q-tip test, if her urethra is partially obstructed, that might affect how her bladder functions.\\n\\nWait, but stress incontinence is more about the muscles not closing properly, not the urethral obstruction. So maybe the Q-tip test was to rule out something like a urethral stricture or a uretal obstruction. If it's positive, it might suggest she has some obstruction, but that's not directly related to stress incontinence.\\n\\nSo focusing back on the cystometry: residual volume is usually normal in stress incontinence because there's no retention at night. Detrusor contractions are increased because the bladder doesn't empty properly. This would cause the high pressure in the bladder during activities like coughing, leading to leakage.\\n\\nI think the key points are that residual volume is normal, and detrusor contractions are increased. The cystometry would show that her bladder doesn't empty completely, hence the detrusor contractions are strong but not effective, leading to the need for urination and the involuntary loss during activities.\\n\\nI should also consider other possibilities. Could there be a mixed diagnosis, like having both stress and urge incontinence? The question doesn't mention urgency, but sometimes these conditions can coexist. If she had urge incontinence, her bladder would have a normal residual volume but increased contractions, but since she doesn't leak at night, it's more likely stress.\\n\\nSo putting it all together, the most likely findings are normal residual volume and increased detrusor contractions.\\n</think>\\n\\n**Answer:**\\n\\nCystometry for this 61-year-old woman would most likely reveal a **normal residual volume** and **increased detrusor contractions**. \\n\\n- **Residual Volume:** The normal finding is consistent with the fact that she does not experience leakage at night, indicating that her bladder does not retain urine during the night.\\n- **Detrusor Contractions:** The increased detrusor contractions are likely due to the stress urinary incontinence, which typically involves weak pelvic floor muscles or urethral issues, leading to incomplete bladder emptying during activities like coughing or sneezing.\\n\\nThis combination of findings supports a diagnosis of **stress urinary incontinence**, emphasizing the need for appropriate treatment to strengthen pelvic muscles and manage symptoms.<ï½œendâ–ofâ–sentenceï½œ>\"]\n",
            "\n",
            "<think>\n",
            "Okay, so I'm trying to figure out what cystometry would show for this 61-year-old woman. Let me start by breaking down the information given.\n",
            "\n",
            "She has a history of involuntary urine loss when she coughs or sneezes, but she doesn't leak at night. That makes me think of stress urinary incontinence. I remember that stress incontinence is usually due to weak pelvic muscles or urethral issues, and it happens when there's increased abdominal pressure, like from coughing.\n",
            "\n",
            "She underwent a gynecological exam and a Q-tip test. I'm not entirely sure what the Q-tip test entails, but I think it's a way to check for urethral obstruction. If the Q-tip is up high, it might mean the urethra is partially blocked. But I'm not certain, so I should double-check that.\n",
            "\n",
            "Now, considering cystometry, which I know is a test to measure how the bladder behaves. It can show things like how much the bladder can hold (residual volume) and how it contracts (detrusor contractions). If she has stress incontinence, I expect the residual volume to be normal because she doesn't leak at night, which suggests she doesn't have volume issues. But during the Q-tip test, if her urethra is partially obstructed, that might affect how her bladder functions.\n",
            "\n",
            "Wait, but stress incontinence is more about the muscles not closing properly, not the urethral obstruction. So maybe the Q-tip test was to rule out something like a urethral stricture or a uretal obstruction. If it's positive, it might suggest she has some obstruction, but that's not directly related to stress incontinence.\n",
            "\n",
            "So focusing back on the cystometry: residual volume is usually normal in stress incontinence because there's no retention at night. Detrusor contractions are increased because the bladder doesn't empty properly. This would cause the high pressure in the bladder during activities like coughing, leading to leakage.\n",
            "\n",
            "I think the key points are that residual volume is normal, and detrusor contractions are increased. The cystometry would show that her bladder doesn't empty completely, hence the detrusor contractions are strong but not effective, leading to the need for urination and the involuntary loss during activities.\n",
            "\n",
            "I should also consider other possibilities. Could there be a mixed diagnosis, like having both stress and urge incontinence? The question doesn't mention urgency, but sometimes these conditions can coexist. If she had urge incontinence, her bladder would have a normal residual volume but increased contractions, but since she doesn't leak at night, it's more likely stress.\n",
            "\n",
            "So putting it all together, the most likely findings are normal residual volume and increased detrusor contractions.\n",
            "</think>\n",
            "\n",
            "**Answer:**\n",
            "\n",
            "Cystometry for this 61-year-old woman would most likely reveal a **normal residual volume** and **increased detrusor contractions**. \n",
            "\n",
            "- **Residual Volume:** The normal finding is consistent with the fact that she does not experience leakage at night, indicating that her bladder does not retain urine during the night.\n",
            "- **Detrusor Contractions:** The increased detrusor contractions are likely due to the stress urinary incontinence, which typically involves weak pelvic floor muscles or urethral issues, leading to incomplete bladder emptying during activities like coughing or sneezing.\n",
            "\n",
            "This combination of findings supports a diagnosis of **stress urinary incontinence**, emphasizing the need for appropriate treatment to strengthen pelvic muscles and manage symptoms.<ï½œendâ–ofâ–sentenceï½œ>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/19704 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91023e1f63324974beb3269b837bb98c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e895dd5abfef4f118f53a8abf67c6b66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.10 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Unsloth: You must specify a `formatting_func`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f595f7b94527>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrapped_old_generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lora\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/trainer.py\u001b[0m in \u001b[0;36mnew_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0moriginal_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0mfix_zero_training_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 )\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             train_dataset = self._prepare_dataset(\n\u001b[0m\u001b[1;32m    536\u001b[0m                 \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpacking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatting_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             )\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m_prepare_dataset\u001b[0;34m(self, dataset, processing_class, args, packing, formatting_func, dataset_name)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mdo_formatting_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mformatting_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsloth: You must specify a `formatting_func`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unsloth: You must specify a `formatting_func`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDgH2GLIWBOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}